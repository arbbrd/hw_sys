# **sdb_12_8_arb**

## Задание_1

Финансовая компания решила увеличить надёжность работы баз данных и их резервного копирования.

Необходимо описать, какие варианты резервного копирования подходят в случаях:
- Необходимо восстанавливать данные в полном объёме за предыдущий день.
- Необходимо восстанавливать данные за час до предполагаемой поломки.
- Возможен ли кейс, когда при поломке базы происходило моментальное переключение на работающую или починенную базу данных.

Приведите ответ в свободной форме.

## Решение_1

1. Восстановление данных в полном объёме за предыдущий день.

Цель: Point-in-Time Recovery (PITR) на конкретную дату (на конец предыдущего дня).

Рекомендуемая стратегия: Комбинация полных и инкрементальных/дифференциальных бэкапов.

- Полные резервные копии (Full Backup): Выполняются регулярно (например, раз в неделю в воскресенье). Содержат все данные на момент создания бэкапа. Это основа для восстановления.

- Инкрементальные (Incremental) или дифференциальные (Differential) копии:
    - Инкрементальные: Записывают только изменения, произошедшие с момента последнего любого бэкапа (полного или инкрементального). Для восстановления на нужный момент нужна последняя полная копия и все цепочка инкрементальных копий до нужного дня. Быстрее создаются, но медленнее восстанавливаются.
    - Дифференциальные: Записывают изменения, произошедшие с момента последнего полного бэкапа. Для восстановления нужна последняя полная копия и только последняя дифференциальная копия. Создаются дольше инкрементальных, но восстанавливаются быстрее.

План для "данные на вчера":

- Еженедельно: Полный бэкап.
- Ежедневно (по будням): Дифференциальный бэкап (предпочтительнее для быстрого восстановления) или инкрементальный.
- Восстановление: Чтобы получить данные на конец рабочего дня вчера, вы разворачиваете полный бэкап прошлого воскресенья, а затем накатываете дифференциальный бэкап за вчера (или цепочку инкрементальных за понедельник и вторник).

Важное дополнение — Резервное копирование журналов транзакций (Transaction Log Backup):

- Для баз данных (SQL Server, PostgreSQL и др.) критически важно делать бэкапы журналов транзакций каждые 15-30 минут или час.
- Это позволяет восстановить базу на любой момент времени внутри дня, а не только на момент создания дифференциального/инкрементального бэкапа. Для задачи "на вчера" вы восстанавливаете полный+дифференциальный бэкап, а затем накатываете все журналы транзакций до 23:59 предыдущего дня.

2. Восстановление данных за час до предполагаемой поломки.

Цель: Точное восстановление на конкретный момент времени (Point-in-Time Recovery), максимально близкий к сбою.

Рекомендуемая стратегия: Полное резервное копирование + Журнал транзакций (Transaction Log).

Это единственный надежный способ для такой точности.

Как это работает:

- Регулярно создаются полные и, возможно, дифференциальные бэкапы (как в первом кейсе).
- Ключевой элемент: Журналы транзакций резервируются очень часто — каждые 5, 10 или 15 минут. Чем чаще, тем меньше данных потеряется (RPO ≈ период между бэкапами журналов).
- Восстановление: Выполняется в строгой последовательности:
    - Восстановить последний полный бэкап с опцией NORECOVERY.
    - Применить последний дифференциальный бэкап (если используется) с опцией NORECOVERY.
    - Применить все журналы транзакций последовательно, созданные после выбранной точки восстановления. Восстановление журналов можно остановить на конкретный момент времени (например, STOPAT '2023-10-26 14:00:00', что означает "за час до поломки в 15:00").

Итог: Эта стратегия гарантирует восстановление состояния БД на любой момент времени между резервными копиями, минимизируя потерю данных до нескольких минут.

3. Моментальное переключение при поломке (High Availability).

Цель: Не просто восстановить данные, а обеспечить минимальный простой (downtime) сервиса. Это не задача резервного копирования, а задача обеспечения высокой доступности (High Availability — HA).

Да, такой кейс не только возможен, но и является стандартной практикой. Резервное копирование здесь — последний рубеж защиты, а основную работу выполняют другие механизмы.

Подходящие решения:

- Кластеризация с общим хранилищем (Shared-Disk Cluster, например, Windows Server Failover Cluster + SQL Server AlwaysOn FCI):
    - Несколько серверов (узлов) работают с одним физическим диском (SAN).
    - При падении активного узла его роль за несколько секунд переходит на резервный узел.
    - Минус: единая точка отказа — само хранилище.

- Репликация на уровне БД (Database Mirroring, AlwaysOn Availability Groups в SQL Server; Streaming Replication в PostgreSQL):
    - Наиболее гибкое и популярное решение. Данные синхронно или асинхронно реплицируются с основной (primary) базы на одну или несколько вторичных (secondary) реплик на разных серверах.
    - При сбое на основной базе происходит автоматический failover на синхронную реплику. Переключение занимает секунды, данные не теряются (при синхронной репликации).
    - Реплики можно использовать для чтения, что разгружает основную базу.

- Мастер-мастер репликация (Multi-Master Replication):
    - Несколько серверов принимают запись. Подходит для распределенных систем.
    - Сложнее в настройке и разрешении конфликтов.

- Программно-определяемые распределенные СУБД (CockroachDB, YugabyteDB):
    - Имеют встроенную репликацию и отказоустойчивость. Данные автоматически shard'ятся и реплицируются между узлами. Потеря даже нескольких узлов не останавливает работу кластера.

Связь HA и Backup:
Решение высокой доступности не заменяет резервное копирование! Ошибка на уровне приложения (например, ошибочное удаление данных) мгновенно реплицируется на все узлы. Для защиты от таких сценариев всегда нужны традиционные бэкапы, хранящиеся отдельно и с историей.



## Задание_2

С помощью официальной документации приведите пример команды резервирования данных и восстановления БД (pgdump/pgrestore).
Возможно ли автоматизировать этот процесс? Если да, то как?

Приведите ответ в свободной форме.

## Решение_2

1. Резервное копирование с помощью pg_dump.

Базовые команды:

```
# 1. Создание дампа в custom-формате (рекомендуется - позволяет выбирать объекты при восстановлении)
pg_dump -U username -h localhost -d database_name -F c -f backup_file.dump

# 2. Создание дампа в plain SQL-формате
pg_dump -U username -d database_name -f backup_file.sql

# 3. Сжатие дампа на лету
pg_dump -U username -d database_name -F c | gzip > backup_file.dump.gz

# 4. Дамп с дополнительными параметрами (рекомендуемый для продакшена)
pg_dump -U postgres \
        -h localhost \
        -d mydb \
        -F c \           # custom format
        -v \             # verbose mode
        -Z 9 \           # максимальное сжатие
        --clean \        # добавлять команды DROP перед CREATE
        --if-exists \    # использовать IF EXISTS с DROP
        --no-owner \     # не сохранять владельца объектов
        --no-privileges \# не сохранять привилегии
        -f /backups/mydb_$(date +%Y%m%d_%H%M%S).dump
```

Дамп всей кластерной информации (все БД):

```
# Дамп всех БД в SQL формате (не рекомендуется для больших БД)
pg_dumpall -U postgres -f all_databases.sql

# Дамп только глобальных объектов (роли, табличные пространства)
pg_dumpall -U postgres --globals-only -f globals.sql
```

2. Восстановление с помощью pg_restore.

Восстановление в новую БД:
```
# 1. Создать БД для восстановления (если её нет)
createdb -U postgres new_database

# 2. Восстановление из custom-формата
pg_restore -U postgres \
           -h localhost \
           -d new_database \
           -v \                # verbose
           --clean \           # очистить объекты перед созданием
           --if-exists \       # использовать IF EXISTS
           --no-owner \        # не восстанавливать владельца
           --no-privileges \   # не восстанавливать привилегии
           backup_file.dump

# 3. Восстановление только структуры (без данных)
pg_restore -U postgres -d new_database --schema-only backup_file.dump

# 4. Восстановление только данных (со структурой уже созданной)
pg_restore -U postgres -d new_database --data-only backup_file.dump

# 5. Восстановление конкретных таблиц
pg_restore -U postgres -d new_database -t table_name backup_file.dump
```

Восстановление из SQL-формата:

```
psql -U postgres -d new_database -f backup_file.sql
```

3. Автоматизация процесса.

- Shell-скрипт с cron.

Создаем файл /usr/local/bin/backup_postgres.sh:

```
#!/bin/bash

# Конфигурация
BACKUP_DIR="/var/backups/postgres"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="mydb"
USERNAME="postgres"
RETENTION_DAYS=7

# Создаем директорию если её нет
mkdir -p $BACKUP_DIR

# Полный дамп БД
pg_dump -U $USERNAME \
        -d $DB_NAME \
        -F c \
        -Z 9 \
        -f $BACKUP_DIR/${DB_NAME}_${DATE}.dump

# Проверяем успешность выполнения
if [ $? -eq 0 ]; then
    echo "[$DATE] Backup successful: ${DB_NAME}_${DATE}.dump"
    
    # Удаляем старые бэкапы (сохраняем 7 дней)
    find $BACKUP_DIR -name "*.dump" -mtime +$RETENTION_DAYS -delete
    echo "[$DATE] Old backups cleaned"
else
    echo "[$DATE] Backup failed!" >&2
    exit 1
fi

# Опционально: копирование на удаленный сервер
# rsync -avz $BACKUP_DIR/ remote_user@backup.server:/remote/backup/path/
```

Сделаем скрипт исполняемым:

```
chmod +x /usr/local/bin/backup_postgres.sh
```

Добавим в crontab:

```
crontab -e
# Добавить строку:
0 2 * * * /usr/local/bin/backup_postgres.sh >> /var/log/postgres_backup.log 2>&1
```

- Использование pgBackRest.

pgBackRest - профессиональное решение для PostgreSQL с поддержкой:
    - Инкрементальных/дифференциальных бэкапов
    - PITR (Point-in-Time Recovery)
    - Параллельной обработки
    - Дедупликации

Пример конфигурации /etc/pgbackrest.conf:

```
[mydb]
pg1-path=/var/lib/postgresql/12/main

[global]
repo1-path=/var/lib/pgbackrest
repo1-retention-full=2
process-max=4

[global:archive-push]
compress-level=3
```

Команды pgBackRest:

```
# Создание полного бэкапа
pgbackrest --stanza=mydb backup --type=full

# Создание дифференциального бэкапа
pgbackrest --stanza=mydb backup --type=diff

# Восстановление на определенное время
pgbackrest --stanza=mydb restore --type=time --target="2025-12-12 14:30:00"
```


## Задание_3

С помощью официальной документации приведите пример команды инкрементного резервного копирования базы данных MySQL.
В каких случаях использование реплики будет давать преимущество по сравнению с обычным резервным копированием?

Приведите ответ в свободной форме.

## Решение_3

Согласно документации MySQL, для инкрементных бэкапов используются бинарные логи.

1. Включаем бинарное логирование.

В конфигурационном файле MySQL (/etc/my.cnf или /etc/mysql/mysql.conf.d/mysqld.cnf):

```
[mysqld]
server-id = 1
log-bin = /var/log/mysql/mysql-bin.log
expire_logs_days = 7
max_binlog_size = 100M
binlog_format = ROW  # Рекомендуется ROW для надежности
```

2. Перезапускаем MySQL и создаем полный бэкап с отметкой позиции в бинарном логе:

```
# Создаем полный бэкап и фиксируем позицию в бинарном логе
mysqldump --all-databases \
          --single-transaction \
          --flush-logs \
          --master-data=2 \
          --routines \
          --triggers \
          --events \
          > full_backup_$(date +%Y%m%d).sql

# Альтернатива с физическим бэкапом (для InnoDB)
mysql -e "FLUSH TABLES WITH READ LOCK;"
cp -R /var/lib/mysql /backups/full_$(date +%Y%m%d)
mysql -e "UNLOCK TABLES;"
```

3. Создаем инкрементальные бэкапы (регулярно):

```
# 1. Сначала принудительно ротируем бинарный лог
mysql -e "FLUSH BINARY LOGS;"

# 2. Копируем все бинарные логи, кроме текущего активного
# Определяем текущий активный бинарный лог
CURRENT_BINLOG=$(mysql -e "SHOW MASTER STATUS\G" | grep File: | awk '{print $2}')

# Копируем все бинарные логи, кроме текущего
cp /var/log/mysql/mysql-bin.* /backups/binlogs/

# 3. Или используем mysqlbinlog для извлечения изменений с определенной позиции
mysqlbinlog --read-from-remote-server \
            --host=localhost \
            --raw \
            --stop-never \
            --result-file=/backups/incremental/ \
            mysql-bin.000001

# 4. Пример инкрементного бэкапа через утилиту mysqlbinlog
# (создаем бэкап изменений с определенной GTID или позиции)
mysqlbinlog --start-datetime="2023-10-27 00:00:00" \
            --stop-datetime="2023-10-27 23:59:59" \
            /var/log/mysql/mysql-bin.00000* > incremental_$(date +%Y%m%d).sql
```

4. Автоматизация через скрипт:

```
#!/bin/bash
# incremental_mysql_backup.sh

BACKUP_DIR="/backups/mysql"
FULL_BACKUP_DIR="$BACKUP_DIR/full"
INC_BACKUP_DIR="$BACKUP_DIR/incremental"
CONFIG_FILE="/etc/mysql/my.cnf"
DATE=$(date +%Y%m%d_%H%M%S)
LOG_FILE="/var/log/mysql_backup.log"

# Функция для логирования
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# Проверяем, нужен ли полный бэкап (раз в неделю)
DAY_OF_WEEK=$(date +%u)  # 1-понедельник, 7-воскресенье

if [ $DAY_OF_WEEK -eq 7 ] || [ ! -f "$FULL_BACKUP_DIR/latest_full_backup" ]; then
    log "Создание полного бэкапа..."
    
    # Полный бэкап с фиксацией позиции бинарного лога
    mysqldump --all-databases \
              --single-transaction \
              --flush-logs \
              --master-data=2 \
              --routines \
              --triggers \
              --events \
              --result-file="$FULL_BACKUP_DIR/full_$DATE.sql" 2>> $LOG_FILE
    
    # Сохраняем информацию о позиции в бинарном логе
    mysql -e "SHOW MASTER STATUS\G" > "$FULL_BACKUP_DIR/master_status_$DATE.txt"
    
    # Сжимаем бэкап
    gzip "$FULL_BACKUP_DIR/full_$DATE.sql"
    
    # Сохраняем метку времени последнего полного бэкапа
    echo $DATE > "$FULL_BACKUP_DIR/latest_full_backup"
    
    log "Полный бэкап создан: full_$DATE.sql.gz"
else
    log "Создание инкрементального бэкапа..."
    
    # Ротация бинарных логов
    mysql -e "FLUSH BINARY LOGS;"
    
    # Определяем текущий бинарный лог
    LAST_BACKUP_BINLOG=$(cat $FULL_BACKUP_DIR/last_binlog 2>/dev/null || echo "")
    CURRENT_BINLOG=$(mysql -e "SHOW BINARY LOGS;" | tail -1 | awk '{print $1}')
    
    # Если это первый инкрементальный бэкап после полного
    if [ -z "$LAST_BACKUP_BINLOG" ]; then
        # Получаем бинарный лог из последнего полного бэкапа
        LAST_BACKUP_BINLOG=$(grep "CHANGE MASTER TO" $FULL_BACKUP_DIR/full_*.sql.gz | \
                           head -1 | grep -o "mysql-bin.[0-9]*")
    fi
    
    # Копируем все бинарные логи с последнего сохраненного
    for binlog in $(mysql -e "SHOW BINARY LOGS;" | awk 'NR>1 {print $1}'); do
        if [[ "$binlog" > "$LAST_BACKUP_BINLOG" ]] || [ "$binlog" == "$LAST_BACKUP_BINLOG" ]; then
            cp "/var/log/mysql/$binlog" "$INC_BACKUP_DIR/"
        fi
    done
    
    # Сохраняем имя последнего скопированного бинарного лога
    echo $CURRENT_BINLOG > "$FULL_BACKUP_DIR/last_binlog"
    
    log "Инкрементальный бэкап создан. Скопированы логи с $LAST_BACKUP_BINLOG"
fi

# Очистка старых бэкапов (храним 30 дней)
find $BACKUP_DIR -name "*.sql.gz" -mtime +30 -delete
find $BACKUP_DIR -name "mysql-bin.*" -mtime +30 -delete
```

Репликация наиболее полезна в следующих случаях:

- Критически важные приложения: Для приложений, где простой недопустим или должен быть минимальным (например, финансовые системы, системы онлайн-торговли).
- Приложения с высокой нагрузкой на чтение: Для приложений, где необходимо масштабировать производительность для обработки большого количества запросов на чтение.
- Приложения, требующие географической отказоустойчивости: Для приложений, которые должны быть доступны даже в случае региональных сбоев.